# 1. 화상 분류와 전이학습(VGG)

---

---

[만들면서배우는파이토치딥러닝_전이학습과VGG.pptx](1%20%E1%84%92%E1%85%AA%E1%84%89%E1%85%A1%E1%86%BC%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%8B%E1%85%AA%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%B5%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8(VGG)%20aa98959238d24b52bbde12da100017d2/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C%EB%B0%B0%EC%9A%B0%EB%8A%94%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5%EA%B3%BCVGG.pptx)

# VGG 16이란?

- VGG - 16은 이름처럼 16층이 아닌 총 38층으로 구성되어 있으며 16층은 합성곱 층과 전결합 층의 수를 나타냄(활성화 함수 ReLU, 풀링 층, 드롭 아웃 층 포함 x)

# 파이토치를 활용한 딥러닝 구현 흐름

![Untitled](1%20%E1%84%92%E1%85%AA%E1%84%89%E1%85%A1%E1%86%BC%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%8B%E1%85%AA%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%B5%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8(VGG)%20aa98959238d24b52bbde12da100017d2/Untitled.png)

1. 전처리, 후처리, 네트워크 모델의 입출력 확인
2. 데이터셋 클래스 생성(입력데이터, 라벨)
    
    → 데이터에 대한 전처리 클래스와 인스턴스를 할당하여 파일을 읽을 때 자동으로 전처리가 되도록 설정
    
    → 훈련 데이터, 검증 데이터(그리고 테스트 데이터)에 대한 DataSet 작성
    
3. DataLoader 클래스 생성
    - DataLoader는 Dataset에서 미니 배치를 쉽게 가지고 올 수 있도록 함
    - 훈련 데이터, 검증 데이터, 테스트 데이터의 DataLoader 생성
4. 네트워크 모델 생성
    - 처음부터 스스로 만든 경우
    - 학습된 모델을 로드하여 사용하는 경우
    - 학습된 모델 기반으로 하는 경우
5. 순전파 정의
    - 딥러닝에서의 복잡한 순서를 제대로 전달하기 위해서는 순전파 함수를 정확하게 정의 해야함
6. 손실함수 정의
    - 오차 역전파법을 사용하기 위해 정의 함
7. 최적화 기법 설정
    - 오차 역전파법으로 결합 파라미터의 오차 경사가 구해짐
    - 최적화 방법으로 이 경사를 사용해 결합 파라미터의 수정량을 어떻게 계산할지 결정
8. 학습 / 검증 실시
    - 에포크마다 훈련 데이터와 검증 데이터의 성능을 확인
    - 검증 데이터의 성능을 향상시킬 수 없으면 early stopping을 사용해 조기종료함
9. 테스트 데이터 추론

# 전이학습

- 학습된 모델을 기반으로 최종 출력층을 바꿔 학습하는 기법
- 학습된 모델의 최종 출력층을 보유 중인 데이터에 대응하는 출력층으로 바꾸고, 교체한 출력층의 결합 파라미터를 소량의 데이터로 다시 학습
- 학습된 모델을 기반하는 전이학습은 보유 중인 데이터가 적더라도 뛰어난 성능의 딥러닝을 실현하기 좋음

# 파인튜닝

- 출력층 등을 변경한 모델을 학습된 모델을 기반으로 구축한 후 직접 준비한 데이터로 신경망 모델의 결합 파라미터를 학습 시키는 방법
- 결합 파라미터의 초기값은 학습된 모델의 파라미터를 사용
- 일반적으로 입력층에 가까운 부분의 파라미터는 학습률을 작게(경우에 따라서 변화 없이), 출력층에 가까운 부분의 파라미터는 학습률을 크게 설정
- 전이학습처럼 학습된 모델을 기반으로 하는 파인튜닝은 직접 준비한 데이터가 적어도 높은 성능의 딥러닝을 실현하기 쉬움