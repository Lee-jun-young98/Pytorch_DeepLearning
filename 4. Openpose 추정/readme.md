# 4. 자세 추정(OpenPose)

---

---

# 자세 추정 개요

- 화상에 포함된 여러 인물을 탐지하여 인체 각 부위의 위치를 식별하고 부위를 연결하는 선(링크)를 구하는 기술
- 총 18개 부위를 연결하여 구함

# MSCOCO 데이터셋

- 화상데이터와 함께 영상 분류, 물체 감지, 시맨틱 분할, 자세 추정 정답인 어노테이션을 사용함
- json 형식으로 이루어져 있음
    - 훈련 데이터 : COCO, 검증 데이터 : COCO_val
    - isValidation : 훈련데이터 0.0, 검증 데이터 1.0
    - img_paths : 화상 데이터 링크
    - num_keypoints : 사진의 주요 인물 인체 부위가 어노테이션 몇 개로 저장되어있는지 확인(최대 17개)
    - joint self : 목 이외 17개 부위의 x, y 좌표와 해당 부위의 시인성 정보 포함
    - scale_provided : 주요 인물을 둘러싼 바운딩 박스의 높이가 368 픽셀의 몇 배인지 나타냄
    - joint_others : 화상 내 다른 이물의 부위 정보 저장

# 오픈포즈를 구성하는 모듈

![KakaoTalk_20220302_132535602.jpg](4%20%E1%84%8C%E1%85%A1%E1%84%89%E1%85%A6%20%E1%84%8E%E1%85%AE%E1%84%8C%E1%85%A5%E1%86%BC(OpenPose)%208138ca71640f467f98d4a5fcc40edec4/KakaoTalk_20220302_132535602.jpg)

- 화상의 특징량을 추출하는 Feature 모듈
- 히트맵과 PAFs를 출력하는 Stage 모듈
    - PAFs : 부위 간의 연결성을 나타냄
1. 전처리 된 화상데이터는 Feture 모듈에 입력되어 128채널의 특징량으로 변환
    1. 블록 1-1은 PAFs를 출력하는 서브 네트워크
    2. 블록 1-2은 히트맵을 출력하는 서브 네트워크
2. 스테이지2에서는 스테이지 1의 출력과 feature 모듈의 출력을 더한 185  x 46 x 46의 크기로 스테이지 2에 진입
    1. 블록 2-1은 PAFs를 출력하는 서브 네트워크
    2. 블록 2-2는 히트맵을 출력하는 서브 네트워크
3. 스트에지 3 ~ 5를 반복 후 스테이지 6에서 출력한 PAFs 및 히트맵을 사용하여 최종 자세를 추정